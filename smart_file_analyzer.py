"""
æ™ºèƒ½æ–‡ä»¶æ•°æ®åˆ†æå™¨

æ”¯æŒä»æŒ‡å®šè·¯å¾„è¯»å–å„ç§æ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼Œå¹¶è¿›è¡ŒAIé©±åŠ¨çš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–
"""
import pandas as pd
import requests
import matplotlib.pyplot as plt
import matplotlib
import os
import json
from pathlib import Path
from typing import Optional, Dict, Any, List

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False


class FileDataAnalyzer:
    """æ™ºèƒ½æ–‡ä»¶æ•°æ®åˆ†æå™¨"""
    
    def __init__(self, ollama_model: str = "codellama:7b", ollama_url: str = "http://localhost:11434"):
        self.model = ollama_model
        self.ollama_url = ollama_url
        self.supported_formats = {
            '.csv': self._read_csv,
            '.xlsx': self._read_excel,
            '.xls': self._read_excel,
            '.json': self._read_json,
            '.parquet': self._read_parquet,
            '.tsv': self._read_tsv,
            '.txt': self._read_txt
        }
        
    def _read_csv(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–CSVæ–‡ä»¶"""
        return pd.read_csv(file_path, **kwargs)
    
    def _read_excel(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–Excelæ–‡ä»¶"""
        return pd.read_excel(file_path, **kwargs)
    
    def _read_json(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–JSONæ–‡ä»¶"""
        return pd.read_json(file_path, **kwargs)
    
    def _read_parquet(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–Parquetæ–‡ä»¶"""
        return pd.read_parquet(file_path, **kwargs)
    
    def _read_tsv(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–TSVæ–‡ä»¶"""
        return pd.read_csv(file_path, sep='\t', **kwargs)
    
    def _read_txt(self, file_path: str, **kwargs) -> pd.DataFrame:
        """è¯»å–TXTæ–‡ä»¶ï¼ˆå‡è®¾æ˜¯åˆ†éš”ç¬¦åˆ†éš”çš„æ•°æ®ï¼‰"""
        # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
        separators = [',', '\t', ';', '|', ' ']
        for sep in separators:
            try:
                df = pd.read_csv(file_path, sep=sep, **kwargs)
                if len(df.columns) > 1:
                    return df
            except:
                continue
        # å¦‚æœéƒ½å¤±è´¥ï¼ŒæŒ‰è¡Œè¯»å–
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        return pd.DataFrame({'content': [line.strip() for line in lines]})
    
    def read_file(self, file_path: str, **kwargs) -> Optional[pd.DataFrame]:
        """
        ä»æŒ‡å®šè·¯å¾„è¯»å–æ•°æ®æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            **kwargs: ä¼ é€’ç»™è¯»å–å‡½æ•°çš„é¢å¤–å‚æ•°
            
        Returns:
            DataFrameæˆ–None
        """
        file_path = Path(file_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        # è·å–æ–‡ä»¶æ‰©å±•å
        file_ext = file_path.suffix.lower()
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒè¯¥æ ¼å¼
        if file_ext not in self.supported_formats:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            print(f"æ”¯æŒçš„æ ¼å¼: {list(self.supported_formats.keys())}")
            return None
        
        try:
            print(f"ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")
            df = self.supported_formats[file_ext](str(file_path), **kwargs)
            print(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼Œå½¢çŠ¶: {df.shape}")
            return df
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def list_directory(self, dir_path: str) -> List[str]:
        """
        åˆ—å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰æ”¯æŒçš„æ•°æ®æ–‡ä»¶
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        dir_path = Path(dir_path)
        if not dir_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return []
        
        files = []
        for file_path in dir_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in self.supported_formats:
                files.append(str(file_path))
        
        return sorted(files)
    
    def chat_with_llm(self, prompt: str) -> str:
        """ä¸LLMå¯¹è¯"""
        url = f"{self.ollama_url}/api/generate"
        data = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        
        try:
            response = requests.post(url, json=data, timeout=120)
            if response.status_code == 200:
                return response.json().get('response', '')
            else:
                return f"é”™è¯¯: HTTP {response.status_code}"
        except Exception as e:
            return f"è¯·æ±‚å¤±è´¥: {str(e)}"
    
    def analyze_file(self, file_path: str, questions: List[str] = None, **read_kwargs) -> Dict[str, Any]:
        """
        åˆ†ææŒ‡å®šæ–‡ä»¶çš„æ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            questions: åˆ†æé—®é¢˜åˆ—è¡¨
            **read_kwargs: è¯»å–æ–‡ä»¶çš„é¢å¤–å‚æ•°
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è¯»å–æ•°æ®
        df = self.read_file(file_path, **read_kwargs)
        if df is None:
            return {"error": "æ— æ³•è¯»å–æ–‡ä»¶"}
        
        # é»˜è®¤é—®é¢˜
        if questions is None:
            questions = [
                "è¯·åˆ†æè¿™ä¸ªæ•°æ®é›†çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯",
                "æ•°æ®ä¸­æœ‰å“ªäº›ä¸»è¦çš„è¶‹åŠ¿å’Œæ¨¡å¼ï¼Ÿ",
                "æœ‰ä»€ä¹ˆå¼‚å¸¸å€¼æˆ–éœ€è¦æ³¨æ„çš„æ•°æ®è´¨é‡é—®é¢˜å—ï¼Ÿ",
                "åŸºäºè¿™äº›æ•°æ®ï¼Œä½ æœ‰ä»€ä¹ˆä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®ï¼Ÿ"
            ]
        
        # æ•°æ®é¢„è§ˆ
        print(f"\nğŸ“Š æ•°æ®é¢„è§ˆ:")
        print(f"æ–‡ä»¶: {file_path}")
        print(f"å½¢çŠ¶: {df.shape}")
        print(f"åˆ—å: {list(df.columns)}")
        print("\nå‰5è¡Œæ•°æ®:")
        print(df.head())
        
        # æ•°æ®ç±»å‹ä¿¡æ¯
        print(f"\nğŸ“‹ æ•°æ®ç±»å‹:")
        print(df.dtypes)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(df.describe())
        
        # AIåˆ†æ
        results = {"file_info": {
            "path": str(file_path),
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": df.dtypes.to_dict()
        }, "analyses": []}
        
        for i, question in enumerate(questions, 1):
            print(f"\nğŸ¤” åˆ†æé—®é¢˜ {i}: {question}")
            
            # æ„å»ºè¯¦ç»†æç¤º
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹æ•°æ®å¹¶å›ç­”é—®é¢˜ã€‚

æ–‡ä»¶ä¿¡æ¯:
- è·¯å¾„: {file_path}
- å½¢çŠ¶: {df.shape}
- åˆ—å: {list(df.columns)}

æ•°æ®é¢„è§ˆ:
{df.head().to_string()}

æ•°æ®ç»Ÿè®¡:
{df.describe().to_string()}

é—®é¢˜: {question}

è¯·æä¾›:
1. è¯¦ç»†çš„æ•°æ®åˆ†æ
2. å…³é”®å‘ç°å’Œæ´å¯Ÿ
3. å®ç”¨çš„å»ºè®®
4. ç”¨ä¸­æ–‡å›ç­”ï¼Œæ¡ç†æ¸…æ™°
"""
            
            answer = self.chat_with_llm(prompt)
            print(f"ğŸ“Š AIåˆ†æç»“æœ:\n{answer}")
            
            results["analyses"].append({
                "question": question,
                "answer": answer
            })
            print("-" * 80)
        
        # ç”Ÿæˆå›¾è¡¨
        chart_path = self.generate_charts(df, file_path)
        results["chart_path"] = chart_path
        
        return results
    
    def generate_charts(self, df: pd.DataFrame, file_path: str) -> str:
        """ä¸ºæ•°æ®ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            # ç¡®å®šæ•°å€¼åˆ—å’Œåˆ†ç±»åˆ—
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            # åˆ›å»ºå›¾è¡¨
            fig_size = (16, 12)
            fig, axes = plt.subplots(2, 3, figsize=fig_size)
            fig.suptitle(f'æ•°æ®åˆ†ææŠ¥å‘Š - {Path(file_path).name}', fontsize=16, fontweight='bold')
            
            # 1. æ•°æ®å½¢çŠ¶ä¿¡æ¯
            ax1 = axes[0, 0]
            ax1.text(0.1, 0.5, f"""
ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯

æ–‡ä»¶: {Path(file_path).name}
è¡Œæ•°: {df.shape[0]:,}
åˆ—æ•°: {df.shape[1]}
æ•°å€¼åˆ—æ•°: {len(numeric_cols)}
åˆ†ç±»åˆ—æ•°: {len(categorical_cols)}
ç¼ºå¤±å€¼: {df.isnull().sum().sum()}
å†…å­˜ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024:.1f} KB
            """, transform=ax1.transAxes, fontsize=10, verticalalignment='center',
                     bbox=dict(boxstyle='round', facecolor='lightblue'))
            ax1.set_title('æ•°æ®é›†æ¦‚è§ˆ')
            ax1.axis('off')
            
            # 2. æ•°å€¼åˆ—åˆ†å¸ƒï¼ˆå¦‚æœæœ‰ï¼‰
            ax2 = axes[0, 1]
            if numeric_cols:
                # é€‰æ‹©å‰å‡ ä¸ªæ•°å€¼åˆ—
                cols_to_plot = numeric_cols[:3]
                for i, col in enumerate(cols_to_plot):
                    ax2.hist(df[col].dropna(), alpha=0.7, label=col, bins=20)
                ax2.set_title('æ•°å€¼åˆ—åˆ†å¸ƒ')
                ax2.legend()
            else:
                ax2.text(0.5, 0.5, 'æ— æ•°å€¼åˆ—', ha='center', va='center', transform=ax2.transAxes)
                ax2.set_title('æ•°å€¼åˆ—åˆ†å¸ƒ')
            
            # 3. ç¼ºå¤±å€¼åˆ†æ
            ax3 = axes[0, 2]
            missing_data = df.isnull().sum()
            if missing_data.sum() > 0:
                missing_data = missing_data[missing_data > 0].sort_values(ascending=True)
                if len(missing_data) > 0:
                    ax3.barh(range(len(missing_data)), missing_data.values)
                    ax3.set_yticks(range(len(missing_data)))
                    ax3.set_yticklabels(missing_data.index)
                    ax3.set_title('ç¼ºå¤±å€¼ç»Ÿè®¡')
                    ax3.set_xlabel('ç¼ºå¤±å€¼æ•°é‡')
            else:
                ax3.text(0.5, 0.5, 'æ— ç¼ºå¤±å€¼', ha='center', va='center', transform=ax3.transAxes)
                ax3.set_title('ç¼ºå¤±å€¼ç»Ÿè®¡')
            
            # 4. åˆ†ç±»åˆ—åˆ†å¸ƒï¼ˆå¦‚æœæœ‰ï¼‰
            ax4 = axes[1, 0]
            if categorical_cols:
                col = categorical_cols[0]
                value_counts = df[col].value_counts().head(10)
                ax4.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
                ax4.set_title(f'{col} åˆ†å¸ƒ')
            else:
                ax4.text(0.5, 0.5, 'æ— åˆ†ç±»åˆ—', ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('åˆ†ç±»åˆ—åˆ†å¸ƒ')
            
            # 5. ç›¸å…³æ€§çŸ©é˜µï¼ˆå¦‚æœæœ‰å¤šä¸ªæ•°å€¼åˆ—ï¼‰
            ax5 = axes[1, 1]
            if len(numeric_cols) > 1:
                corr_matrix = df[numeric_cols].corr()
                im = ax5.imshow(corr_matrix, cmap='coolwarm', aspect='auto')
                ax5.set_xticks(range(len(numeric_cols)))
                ax5.set_yticks(range(len(numeric_cols)))
                ax5.set_xticklabels(numeric_cols, rotation=45)
                ax5.set_yticklabels(numeric_cols)
                ax5.set_title('ç›¸å…³æ€§çŸ©é˜µ')
                
                # æ·»åŠ æ•°å€¼æ ‡æ³¨
                for i in range(len(numeric_cols)):
                    for j in range(len(numeric_cols)):
                        ax5.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', 
                                ha='center', va='center')
            else:
                ax5.text(0.5, 0.5, 'æ•°å€¼åˆ—ä¸è¶³', ha='center', va='center', transform=ax5.transAxes)
                ax5.set_title('ç›¸å…³æ€§çŸ©é˜µ')
            
            # 6. æ•°æ®è´¨é‡æ‘˜è¦
            ax6 = axes[1, 2]
            quality_info = f"""
ğŸ“‹ æ•°æ®è´¨é‡æ‘˜è¦

å®Œæ•´æ€§: {((df.size - df.isnull().sum().sum()) / df.size * 100):.1f}%
å”¯ä¸€æ€§: {(df.nunique().sum() / df.size * 100):.1f}%
æ•°å€¼åˆ—å æ¯”: {(len(numeric_cols) / len(df.columns) * 100):.1f}%

ğŸ” æ£€æŸ¥é¡¹ç›®:
- é‡å¤è¡Œ: {df.duplicated().sum()}
- ç©ºç™½å­—ç¬¦ä¸²: {(df == '').sum().sum() if df.select_dtypes(include=['object']).size > 0 else 0}
- é›¶å€¼æ•°é‡: {(df == 0).sum().sum() if len(numeric_cols) > 0 else 0}
            """
            ax6.text(0.1, 0.5, quality_info, transform=ax6.transAxes, fontsize=9,
                     verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightyellow'))
            ax6.set_title('æ•°æ®è´¨é‡è¯„ä¼°')
            ax6.axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            chart_filename = f"analysis_{Path(file_path).stem}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(chart_filename, dpi=300, bbox_inches='tight')
            print(f"âœ… å›¾è¡¨å·²ä¿å­˜ä¸º: {chart_filename}")
            
            plt.show()
            return chart_filename
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
            return None
    
    def interactive_analysis(self):
        """äº¤äº’å¼æ•°æ®åˆ†æ"""
        print("ğŸš€ æ™ºèƒ½æ–‡ä»¶æ•°æ®åˆ†æå™¨")
        print("=" * 50)
        
        while True:
            print("\nğŸ“‹ å¯ç”¨æ“ä½œ:")
            print("1. åˆ†æå•ä¸ªæ–‡ä»¶")
            print("2. æµè§ˆç›®å½•ä¸­çš„æ–‡ä»¶")
            print("3. è‡ªå®šä¹‰åˆ†æé—®é¢˜")
            print("4. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()
            
            if choice == '1':
                self._analyze_single_file()
            elif choice == '2':
                self._browse_directory()
            elif choice == '3':
                self._custom_analysis()
            elif choice == '4':
                print("ğŸ‘‹ å†è§ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    
    def _analyze_single_file(self):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        file_path = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„: ").strip()
        if not file_path:
            return
        
        # è¯¢é—®æ˜¯å¦æœ‰ç‰¹æ®Šçš„è¯»å–å‚æ•°
        print("\nğŸ“‹ å¯é€‰çš„è¯»å–å‚æ•°:")
        print("ä¾‹å¦‚: encoding=utf-8, sep=';', sheet_name=0")
        params_str = input("è¯·è¾“å…¥å‚æ•° (å›è½¦è·³è¿‡): ").strip()
        
        read_kwargs = {}
        if params_str:
            try:
                # ç®€å•è§£æå‚æ•°
                for param in params_str.split(','):
                    if '=' in param:
                        key, value = param.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('\'"')
                        # å°è¯•è½¬æ¢æ•°å€¼
                        if value.isdigit():
                            value = int(value)
                        elif value.replace('.', '').isdigit():
                            value = float(value)
                        read_kwargs[key] = value
            except Exception as e:
                print(f"âš ï¸ å‚æ•°è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®: {e}")
        
        self.analyze_file(file_path, **read_kwargs)
    
    def _browse_directory(self):
        """æµè§ˆç›®å½•"""
        dir_path = input("è¯·è¾“å…¥ç›®å½•è·¯å¾„: ").strip()
        if not dir_path:
            return
        
        files = self.list_directory(dir_path)
        if not files:
            print("âŒ ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ•°æ®æ–‡ä»¶")
            return
        
        print(f"\nğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶:")
        for i, file_path in enumerate(files, 1):
            file_size = Path(file_path).stat().st_size / 1024
            print(f"{i:2d}. {Path(file_path).name} ({file_size:.1f} KB)")
        
        try:
            choice = int(input(f"\nè¯·é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶ (1-{len(files)}): "))
            if 1 <= choice <= len(files):
                selected_file = files[choice - 1]
                self.analyze_file(selected_file)
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æ•°å­—")
    
    def _custom_analysis(self):
        """è‡ªå®šä¹‰åˆ†æé—®é¢˜"""
        file_path = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„: ").strip()
        if not file_path:
            return
        
        print("\nğŸ“ è¯·è¾“å…¥åˆ†æé—®é¢˜ (æ¯è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸ):")
        questions = []
        while True:
            question = input().strip()
            if not question:
                break
            questions.append(question)
        
        if not questions:
            print("âŒ æ²¡æœ‰è¾“å…¥é—®é¢˜")
            return
        
        self.analyze_file(file_path, questions)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = FileDataAnalyzer()
    
    # æ£€æŸ¥OllamaæœåŠ¡
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            if models:
                print(f"âœ… OllamaæœåŠ¡æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {[m['name'] for m in models]}")
                analyzer.interactive_analysis()
            else:
                print("âŒ æœªæ‰¾åˆ°Ollamaæ¨¡å‹ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹")
        else:
            print("âŒ OllamaæœåŠ¡å¼‚å¸¸")
    except:
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨")


if __name__ == "__main__":
    main()